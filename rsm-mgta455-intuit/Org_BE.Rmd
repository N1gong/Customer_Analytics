
```{r}
library(tidyverse)
library(radiant)
library(matrixStats)
```

## Part 1: Exploratory Data Analysis:
```{r}
intuit75k <- readr::read_rds(file.path(radiant.data::find_dropbox(), "MGTA455-2019/data/intuit75k.rds"))

### correlations
result <- correlation(
  intuit75k, 
  vars = c(
    "zip_bins", "bizflag", "numords", "dollars", "last", "sincepurch", 
    "version1", "owntaxprod", "upgraded"
  )
)
summary(result)
plot(result, nrobs = 1000)

### "res1" v.s other 
## zip_bins
intuit75k %>%
  group_by(zip_bins) %>%
  mutate(zip_bins_resp = mean(res1 == "Yes")) %>%
  distinct(zip_bins, zip_bins_resp) %>%
  arrange(zip_bins) %>%
  ggplot(aes(x=zip_bins, y=zip_bins_resp, fill = zip_bins)) + geom_bar(stat = 'identity')

## sex
intuit75k %>%
  group_by(sex) %>%
  mutate(sex_resp = mean(res1 == "Yes")) %>%
  distinct(sex, sex_resp) %>%
  arrange(sex) %>%
  ggplot(aes(x=sex, y=sex_resp, fill = sex)) + geom_bar(stat = 'identity')

## bizflag
intuit75k %>%
  group_by(bizflag) %>%
  mutate(bizflag_resp = mean(res1 == "Yes")) %>%
  distinct(bizflag, bizflag_resp) %>%
  arrange(bizflag) %>%
  ggplot(aes(x=bizflag, y=bizflag_resp, fill = bizflag)) + geom_bar(stat = 'identity')
    
## numords
intuit75k %>%
  group_by(numords) %>%
  mutate(numords_resp = mean(res1 == "Yes")) %>%
  distinct(numords, numords_resp) %>%
  arrange(numords) %>%
  ggplot(aes(x=numords, y=numords_resp, fill = numords)) + geom_bar(stat = 'identity')

## dollars
intuit75k %>%
  group_by(dollars) %>%
  mutate(dollars_resp = mean(res1 == "Yes")) %>%
  distinct(dollars, dollars_resp) %>%
  arrange(dollars) %>%
  ggplot(aes(x=dollars, y=dollars_resp, fill = dollars)) + geom_bar(stat = 'identity')

## last
intuit75k %>%
  group_by(last) %>%
  mutate(last_resp = mean(res1 == "Yes")) %>%
  distinct(last, last_resp) %>%
  arrange(last) %>%
  ggplot(aes(x=last, y=last_resp, fill = last)) + geom_bar(stat = 'identity')

## sincepurch
intuit75k %>%
  group_by(sincepurch) %>%
  mutate(sincepurch_resp = mean(res1 == "Yes")) %>%
  distinct(sincepurch, sincepurch_resp) %>%
  arrange(sincepurch) %>%
  ggplot(aes(x=sincepurch, y=sincepurch_resp, fill = sincepurch)) + geom_bar(stat = 'identity')

## version1
intuit75k %>%
  group_by(version1) %>%
  mutate(version1_resp = mean(res1 == "Yes")) %>%
  distinct(version1, version1_resp) %>%
  arrange(version1) %>%
  ggplot(aes(x=version1, y=version1_resp, fill = version1)) + geom_bar(stat = 'identity')

## version1
intuit75k %>%
  group_by(version1) %>%
  mutate(version1_resp = mean(res1 == "Yes")) %>%
  distinct(version1, version1_resp) %>%
  arrange(version1) %>%
  ggplot(aes(x=version1, y=version1_resp, fill = version1)) + geom_bar(stat = 'identity')

## owntaxprod
intuit75k %>%
  group_by(owntaxprod) %>%
  mutate(owntaxprod_resp = mean(res1 == "Yes")) %>%
  distinct(owntaxprod, owntaxprod_resp) %>%
  arrange(owntaxprod) %>%
  ggplot(aes(x=owntaxprod, y=owntaxprod_resp, fill = owntaxprod)) + geom_bar(stat = 'identity')

## upgraded
intuit75k %>%
  group_by(upgraded) %>%
  mutate(upgraded_resp = mean(res1 == "Yes")) %>%
  distinct(upgraded, upgraded_resp) %>%
  arrange(upgraded) %>%
  ggplot(aes(x=upgraded, y=upgraded_resp, fill = upgraded)) + geom_bar(stat = 'identity')


```

In this part, we first explore the relationship among "res1" and the other explanatory variables. We can reach the following conclusions based on the EDA output:

1) The customers in zip_bins = 1 have obviously higher response rate than other zip bin customars.
2) The variables "sex" and "bizflag" have no significant effect on "res1".
3) The variables "last" and "sincepurch" have a nagative relationship. Furthermore, since these two variables have similar meaning, we decide to keep only one of them in the models. After comparing the performance of these two different variables, we finally choose the "last".


```{r}
# create new variable "zip_one" 
intuit75k <- intuit75k %>% mutate(zip_fac = factor(zip_bins),
                                  zip_one = ifelse(zip_fac == 1, TRUE, FALSE))

# create new variable "zip_one" 
intuit75k <- intuit75k %>% mutate(state= substr(zip, 1, 3))

intuit75k %>%
  group_by(state) %>%
  summarize(resp_state = mean(res1 == "Yes"), count = n()) %>%
  arrange(desc(resp_state)) 

intuit75k <- intuit75k %>% mutate(VI = ifelse(substr(zip, 1, 3) == '008', TRUE, FALSE))
```

Based on the output that customers in zip_bines = 1 have obviously higher response rate than other zip bin customars, we create the new variable "zip_one", which equals TRUE when zip_bins = 1 and equals FALSE otherwise. 

Besides that, we did further exploration to find the state with the highest response rate. The result shows that Virginia whose zipcode start with "008" has 1891 responses with response rate of 0.398, which is much higher than the other states. Thus, we create another new variable "VI".



```{r}
mail_cost <- 1.41
sales_margin <- 60
break_even_resp <- (mail_cost / sales_margin)
```


```{r}
perf_eval <- function(df) {
  
  cus <- nrow(df)
  perc_mail <- mean(df$mailto_wave2)
  dat <- filter(df, mailto_wave2 == TRUE)
  resp <- mean(dat$res1 == 'Yes')
  act_resp <- mean(df$res1 == 'Yes') 

  nummail <- sum(df$mailto_wave2)
  mailcost <- nummail * mail_cost

  exp_buyer <- sum(dat$res1 == 'Yes')
  act_buyer <- sum(df$res1 == 'Yes')

  exp_margin <- exp_buyer*sales_margin
  act_margin <- sum(df$res1 == 'Yes') * sales_margin

  profit <- exp_buyer *sales_margin - mailcost
  ROME <- profit / mailcost
  
  AUC <- auc(as.numeric(df$mailto_wave2), df$res1, 'Yes')
  
  prnt <- paste0("Based on our analysis, the number of customers Intuit should mail is ", format_nr(nummail, dec = 0), " that is ", format_nr(perc_mail, perc = TRUE), " of the customers.</br> The response rate for the selected customers is predicted to be ", format_nr(resp, perc = TRUE), ", or, ", format_nr(exp_buyer, dec = 0), " buyers; while the actual response rate is ", format_nr(act_resp, perc = TRUE), ", or, ", format_nr(act_buyer, dec=0), ".</br> The predicted margin is ", format_nr(exp_margin, "$", dec = 2), "; while actual margin is ", format_nr(act_margin, "$", dec=2),  ".</br> The expected profit is ", format_nr(profit, "$", dec = 0), ". The messaging cost is estimated to be ", format_nr(mailcost, "$", dec = 0), " with a ROME of ", format_nr(ROME, perc = FALSE), ".")

  perf <- data.frame(nummail, perc_mail, resp, exp_buyer, exp_margin, profit, mailcost, ROME, AUC, prnt)

}
```

### RFM model
```{r}
## 1. sq. RFM model

intuit75k <- intuit75k %>%
  group_by(zip_fac) %>% 
  mutate(rec = xtile(last, 5)) %>%
  group_by(rec) %>%
  mutate(freq =xtile(numords, 5, rev = TRUE)) %>%
  group_by(rec, freq) %>%
  mutate(mon = xtile(dollars, 5, rev = TRUE)) %>%
  mutate(rfm_sq = paste0(rec, freq, mon)) %>%
  ungroup()
```


### RFM
```{r}
train <- intuit75k %>%
  filter(training == 1) %>%
  group_by(rfm_sq) %>%
  mutate(rfm_resp = mean(res1 == 'Yes'),
         mailto_wave2 = rfm_resp > break_even_resp) %>%
  ungroup()

rfm_id <- train$rfm_sq[train$mailto_wave2 == TRUE]
```

```{r}
val <- intuit75k %>%
  filter(training == 0)


val$mailto_wave2 <- ifelse(val$rfm_sq %in% rfm_id, TRUE, FALSE)

val <- val %>% 
  group_by(rfm_sq) %>% 
  mutate(rfm_resp = mean(res1 == 'Yes')) %>% 
  ungroup()

```  


```{r}
perf_rfm_train <- perf_eval(train)
perf_rfm_val <- perf_eval(val)
```  


### Evaulate RFM
```{r results="asis"}
cat(perf_rfm_train$prnt)
```  

```{r results="asis"}
perf_rfm_val$prnt
```


### Logistic Regression(A)
  
  "zip_one", "numords", "dollars", "last", "version1", "owntaxprod", "upgraded"
```{r}
set.seed(1234)

log_tr_predA <- data.frame(id = train$id)
log_val_predA <- data.frame(id = val$id)

for (i in 1:100) {
  
  t_logA <- sample_n(train, 52500, replace = TRUE)
 
  res_logA <- logistic(
  t_logA, 
  rvar = "res1", 
  evar = c("zip_one", "numords", "dollars", "last", "version1", "owntaxprod", "upgraded"), 
  lev = "Yes", 
  # check = "standardize"
)
  
  pred_logA <- predict(res_logA, pred_data = train)
  pred_logvA <- predict(res_logA, pred_data = val)
  
  log_tr_predA <- store(log_tr_predA, pred_logA, name = paste0("pred_logit", i))
  log_val_predA <- store(log_val_predA, pred_logvA, name = paste0("pred_val_logit", i))
  
}
```  


```{r}
train_lbA <- data.frame(id = log_tr_predA$id, prob_log_lbA = apply(log_tr_predA[, -1], 1, quantile, probs = 0.05))
train <- train %>% 
  left_join(train_lbA, by = 'id')
```

```{r}
val_lbA <- data.frame(id = log_val_predA$id, prob_log_lbA = apply(log_val_predA[, -1], 1, quantile, probs = 0.05))
val <- val %>% 
  left_join(val_lbA, by = 'id')
```


### Logistic Regression(B) - Replace "zip_one" with "VI"
  
  "VI", "numords", "dollars", "last", "version1", "owntaxprod", "upgraded"
```{r}
set.seed(1234)

log_tr_predB <- data.frame(id = train$id)
log_val_predB <- data.frame(id = val$id)

for (i in 1:100) {
  
  t_logB <- sample_n(train, 52500, replace = TRUE)
 
  res_logB <- logistic(
  t_logB, 
  rvar = "res1", 
  evar = c("VI", "numords", "dollars", "last", "version1", "owntaxprod", "upgraded"), 
  lev = "Yes", 
  # check = "standardize"
)
  
  pred_logB <- predict(res_logB, pred_data = train)
  pred_logvB <- predict(res_logB, pred_data = val)
  
  log_tr_predB <- store(log_tr_predB, pred_logB, name = paste0("pred_logit", i))
  log_val_predB <- store(log_val_predB, pred_logvB, name = paste0("pred_val_logit", i))
  
}
```  


```{r}
train_lbB <- data.frame(id = log_tr_predB$id, prob_log_lbB = apply(log_tr_predB[, -1], 1, quantile, probs = 0.05))
train <- train %>% 
  left_join(train_lbB, by = 'id')
```

```{r}
val_lbB <- data.frame(id = log_val_predB$id, prob_log_lbB = apply(log_val_predB[, -1], 1, quantile, probs = 0.05))
val <- val %>% 
  left_join(val_lbB, by = 'id')
```


```{r}
train <- train %>% 
  mutate(mailto_wave2 = prob_log_lbA > break_even_resp)
```


```{r}
val <- val %>% 
  mutate(mailto_wave2 = prob_log_lbA > break_even_resp)
```


```{r}
perf_log_trainA <- perf_eval(train)
perf_log_valA <- perf_eval(val)
```  

```{r results="asis"}
perf_log_trainA$prnt
```  


```{r results="asis"}
perf_log_valA$prnt
```



```{r}
train <- train %>% 
  mutate(mailto_wave2 = prob_log_lbB > break_even_resp)
```


```{r}
val <- val %>% 
  mutate(mailto_wave2 = prob_log_lbB > break_even_resp)
```


```{r}
perf_log_trainB <- perf_eval(train)
perf_log_valB <- perf_eval(val)
```  


```{r echo = FALSE, results="asis"}
perf_log_trainB$prnt
```  


```{r results="asis"}
perf_log_valB$prnt
```  



### Compare
```{r}
perf_2logs <- data.frame(
  name = c("log.train.zip_one", "log.train.VI", "log.val.zip_one", "log.val.VI"),
  Profit = c(perf_log_trainA$profit, perf_log_trainB$profit, perf_log_valA$profit, perf_log_valB$profit),
  ROME = c(perf_log_trainA$ROME, perf_log_trainB$ROME, perf_log_valA$ROME, perf_log_valB$ROME)
)
```

```{r}
visualize(
  perf_2logs,
  xvar = "name",
  yvar = "Profit",
  type = "bar",
  labs = list(title = "compare profit", x = ""),
  custom = TRUE
) +
  geom_text(aes(label = format_nr(Profit, dec = 2)), vjust = 2)


visualize(
  perf_2logs,
  xvar = "name",
  yvar = "ROME",
  type = "bar",
  labs = list(title = "compare ROME", x = ""),
  custom = TRUE
) +
  geom_text(aes(label = format_nr(ROME, dec = 2)), vjust = 2)
```  

```{r echo=FALSE, fig.height=12.92, fig.width=7, dpi=144}
met_eval <- confusion(
  new_intuit, 
  pred = c("prob_log_lbA", "prob_log_lbB"), 
  rvar = "res1", 
  lev = "Yes", 
  cost = 1.41, 
  margin = 60, 
  train = "Both", 
  data_filter = "training == 1"
)
summary(met_eval)
plot(met_eval, custom = TRUE)
```  




### Naive Bayes  

**Created Laplace = 1 to avoid situation where the predictor predict 0 on unseen event**  

```{r include=FALSE}
nb_res <- nb(
  train, 
  rvar = "res1", 
  evar = c("VI", "numords", "dollars", "last", "version1", "owntaxprod", "upgraded"), 
  laplace = 1
)
summary(nb_res)
```


```{r echo=FALSE}
pred <- predict(nb_res, pred_data = train)
print(pred, n = 10)
train <- store(train, pred, name = "pred_nb")
```

```{r include=FALSE}
train <- train %>% 
  mutate(mailto_wave2 = pred_nb > break_even_resp)
```

```{r echo=FALSE}
pred <- predict(nb_res, pred_data = val)
print(pred, n = 10)
val <- store(val, pred, name = "pred_nb")
```

```{r include=FALSE}
val <- val %>% 
  mutate(mailto_wave2 = pred_nb > break_even_resp)
```

```{r include=FALSE}
perf_nb_train <- perf_eval(train)
perf_nb_val <- perf_eval(val)
```  


```{r results="asis"}
perf_nb_train$prnt
```  


```{r results="asis"}
perf_nb_val$prnt
```  




### NN  

**From the network plot we can see that 

```{r echo=FALSE, fig.height=5.38, fig.width=7, dpi=144}
resultnn <- nn(
  intuit75k, 
  rvar = "res1", 
  evar = c("VI", "numords", "dollars", "last", "version1", "owntaxprod", "upgraded"), 
  lev = "Yes", 
  size = 2, 
  seed = 1234, 
  data_filter = "training == 1"
)

plot(resultnn, plots = "net", custom = FALSE)

plot(resultnn, plots = "olden", custom = FALSE)
```

```{r include=FALSE}
nn_pred_tr <- read_rds("NNTr.rds")
nn_pred_val <- read_rds("NNVal.rds")
```

  
```{r include=FALSE}
train_lbnn1 <- data.frame(id = nn_pred_tr$id, prob_nn_lb1 = apply(nn_pred_tr[, -1], 1, quantile, probs = 0.05))
train <- train %>% 
  left_join(train_lbnn1, by = 'id')
```  


```{r include=FALSE}
val_lbnn1 <- data.frame(id = nn_pred_val$id, prob_nn_lb1 = apply(nn_pred_val[, -1], 1, quantile, probs = 0.05))
val <- val %>% 
  left_join(val_lbnn1, by = 'id')
```

```{r include=FALSE}
train <- train %>% 
  mutate(mailto_wave2 = prob_nn_lb1 > break_even_resp)
```

```{r include=FALSE}
val <- val %>% 
  mutate(mailto_wave2 = prob_nn_lb1 > break_even_resp)
```


```{r include=FALSE}
perf_nn_train <- perf_eval(train)
perf_nn_val <- perf_eval(val)
```  


```{r results="asis"}
perf_nn_train$prnt
```


```{r results="asis"}
perf_nn_val$prnt
```




### Evaluate Performance for all models  

```{r include=FALSE}
perf_all_trn <- data.frame(
  name = c("RFM. sq", "logit. lb", "naive.Bayes", "Neural Network"),
  Profit = c(perf_rfm_train$profit, perf_log_trainB$profit, perf_nb_train$profit, perf_nn_train$profit),
  ROME = c(perf_rfm_train$ROME, perf_log_trainB$ROME, perf_nb_train$ROME, perf_nn_train$ROME)
)
```  


```{r include=FALSE}
perf_all_val <- data.frame(
  name = c("RFM. sq", "logit. lb", "naive.Bayes", "Neural Network"),
  Profit = c(perf_rfm_val$profit, perf_log_valB$profit, perf_nb_val$profit, perf_nn_val$profit),
  ROME = c(perf_rfm_val$ROME, perf_log_valB$ROME, perf_nb_val$ROME, perf_nn_val$ROME)
)
```


```{r echo=FALSE}
## Train
visualize(
  perf_all_trn,
  xvar = "name",
  yvar = "Profit",
  type = "bar",
  labs = list(title = "traing profit", x = ""),
  custom = TRUE
) +
  geom_text(aes(label = format_nr(Profit, dec = 2)), vjust = 2)

## Val
visualize(
  perf_all_val,
  xvar = "name",
  yvar = "Profit",
  type = "bar",
  labs = list(title = "validation profit", x = ""),
  custom = TRUE
) +
  geom_text(aes(label = format_nr(Profit, dec = 2)), vjust = 2)

```  


### Metrics
```{r include=FALSE}
new_intuit <- rbind(train, val)
```  


```{r echo=FALSE, fig.height=21.54, fig.width=7.54, dpi=144}
eval_class <- evalbin(
  new_intuit, 
  pred = c("rfm_resp", "prob_log_lbB", "pred_nb", "prob_nn_lb1"), 
  rvar = "res1", 
  lev = "Yes", 
  cost = 1.41, 
  margin = 60, 
  train = "Both", 
  data_filter = "training == 1"
)
summary(eval_class, prn = FALSE)
plot(
  eval_class, 
  plots = c("lift", "gains", "profit", "rome"), 
  custom = FALSE
)
```  


```{r echo=FALSE, fig.height=12.92, fig.width=7, dpi=144}
eval_conf <- confusion(
  new_intuit, 
  pred = c("rfm_resp", "prob_log_lbB", "pred_nb", "prob_nn_lb1"), 
  rvar = "res1", 
  lev = "Yes", 
  cost = 1.41, 
  margin = 60, 
  train = "Both", 
  data_filter = "training == 1"
)
summary(eval_conf)
plot(eval_conf, custom = TRUE)
```
