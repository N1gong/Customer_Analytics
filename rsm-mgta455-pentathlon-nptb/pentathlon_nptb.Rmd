---
title: "Pentathlon III: Next Product to Buy Modeling"
output: html_document
---

* Team-lead gitlab id: rsm-n1gong
* Team-lead gitlab username: Nawen Gong
* Group number: 12
* Group name: Team 12
* Team member names: Nawen Gong, Zichen Huang, Xinyue Tao, Zheng Shan

```{r r_setup, include = FALSE}
## initial settings
knitr::opts_chunk$set(
  comment = NA,
  echo = TRUE,
  error = TRUE,
  cache = FALSE,
  message = FALSE,
  dpi = 96,
  warning = FALSE
)

## width to use when printing tables etc.
options(
  width = 250,
  scipen = 100,
  max.print = 5000,
  stringsAsFactors = FALSE
)

## load radiant packages if neededi
if (!exists("r_environment")) library(radiant)
```

<style>
.table {
  width: auto;
}
ul, ol {
  padding-left: 18px;
}
pre, code, pre code {
  overflow: auto;
  white-space: pre;
  word-wrap: normal;
  background-color: #ffffff;
}
</style>

## Setup

Please complete this Rmarkdown document by answering the questions in `pentathlon-nptb.pdf` on Dropbox (week8/readings/). The code block below will load the data you need. Please DO NOT change the code used to load the data. Create an HTML file with all your results and comments and push both the Rmarkdown and HTML file to GitLab when you are done. As always, all results MUST be reproducible (i.e., the TA and I must be able to recreate the HTML from the R-markdown file without changes or errors).

Good luck!

```{r include=FALSE}
## Loading the data from Dropbox/MGTA455-2019/data/
pentathlon_nptb <- readr::read_rds(file.path(radiant.data::find_dropbox(), "MGTA455-2019/data/pentathlon_nptb.rds"))
```

## Question answers

```{r include=FALSE}
library(radiant)
library(tidyverse)
library(caret)
library(ranger)
library(keras)
library(gbm)
```

Separate datasets into train/val/reps

```{r include=FALSE}
train <- filter(pentathlon_nptb, training == 1&representative == 0)
val <- filter(pentathlon_nptb, training == 0&representative == 0)
reps <- filter(pentathlon_nptb, is.na(training))
```  


#### parameters to use 
```{r}
## list response (rvar), explanatory (evar)  and interaction (int) variables
rvar <- "buyer"

evar <- c("message","age", "gender", "income", "education", "children", "freq_endurance",
          "freq_strength", "freq_water", "freq_team", "freq_backcountry", "freq_winter",
          "freq_racquet")

int <- c("message:age", "message:gender", "message:income", "message:education", 
         "message:children", "message:freq_endurance", "message:freq_strength",
         "message:freq_water", "message:freq_team", "message:freq_backcountry", 
         "message:freq_winter", "message:freq_racquet")

lev <- "yes"
```  


#### Create dataframe for model evaluation  

```{r echo=FALSE}
## setup a tibble to use for evaluation
eval_dat <- tibble::tibble(
  buyer = pentathlon_nptb$buyer, 
  training = pentathlon_nptb$training
)
head(eval_dat)
```  

  
***  



## Model Evaluation and Selection  


  

## Logistic 
```{r echo=FALSE}
result <- logistic(
  pentathlon_nptb,  
  rvar = rvar,  evar = evar,  lev = lev, int = int, 
  data_filter = "training == 1"
)
summary(result)
eval_dat$logit <- predict(result, pentathlon_nptb)$Prediction
head(eval_dat)
```  



## Ctree(Radiant classification tree model)

#### Train (default parameters)
```{r echo=FALSE}
res_ctr <- crtree(
  train, 
  rvar = "buyer", 
  evar = c(
    "message", "age", "gender", "income", "education", "children", 
    "freq_endurance", "freq_strength", "freq_water", "freq_team", 
    "freq_backcountry", "freq_winter", "freq_racquet"
  ), 
  type = "classification", 
  lev = "yes", 
  cost = 0.6, 
  margin = 1
)
summary(res_ctr, prn = FALSE)
```


#### tune the model using cross validation  
**Given the provided tuning grid, the pruning complexity parameter should be set to 0 or the number of nodes set to 16**  


```{r echo=FALSE}
tree_CV <- read_rds("tree_cv.rds")
tree_CV[1,]
```




#### Now trian with the best parameter and test on the whole datasets

```{r echo=FALSE}
res_ctr1 <- crtree(
  train, 
  rvar = "buyer", 
  evar = c(
    "message", "age", "gender", "income", "education", "children", 
    "freq_endurance", "freq_strength", "freq_water", "freq_team", 
    "freq_backcountry", "freq_winter", "freq_racquet"
  ), 
  type = "classification", 
  lev = "yes", 
  nodes = 16, 
  pcp = 0,
  cost = 0.6, 
  margin = 1
)
summary(res_ctr1, prn = FALSE)


pred_ctr <- predict(res_ctr1, pred_data = pentathlon_nptb)
eval_dat$ctree <- pred_ctr$Prediction
head(eval_dat)
```  
  


## Nerual Network  


#### using radiant.model::nn 
```{r}
res_nn <- read_rds("res_nn.rds")
```
res_nn <- nn(
  train, 
  rvar = rvar, evar = evar, lev = lev, 
  size = 5, 
  decay = 0.5, 
  data_filter = "training == 1",
  seed = 1234
)
summary(res_nn)
saveRDS(res_nn, "res_nn.rds")

```{r echo=FALSE}
vals_nn <- read_rds("val_cv.rds")
## using cross-validation to determine the best values for size and decay
## using AUC to select the best fitting model
# vals_nn <- cv.nn(res_nn, size = seq(4, 10, 2), decay = seq(0, 0.5, 0.1))
head(vals_nn)
```  

#### based on cross validation the best nn has 6 nodes in the hidden layer and decay set to 0.3

```{r echo=FALSE}
res_nn1 <- read_rds("res_nn1.rds")
#res_nn1 <- nn(
 # pentathlon_nptb, 
  #rvar = rvar, evar = evar, lev = lev, 
  #size = vals_nn$size[1],
  #decay = vals_nn$decay[1],
  #data_filter = "training == 1",
  #seed = 1234
#)
#saveRDS(res_nn1, "res_nn1.rds")
summary(res_nn1)
eval_dat$NN <- predict(result, pentathlon_nptb)$Prediction
```  



## GBM


Preprocessing data  

```{r}
dat_train <- train[, -c(17:25, 1, 3)]
dat_train$buyer <- ifelse(dat_train$buyer == 'yes', 1, 0)
dat_tree <- model.matrix(~.+0,data =dat_train[,-1]) 
dat_tree <- data.frame(buyer = dat_train[,1], dat_tree)

## Test set
dat_val <- val[, -c(17:25, 1, 3)]
dat_val$buyer <- ifelse(dat_val$buyer == 'yes', 1, 0)
dat_tree_val <- model.matrix(~.+0,data =dat_val[,-1]) 
dat_tree_val <- data.frame(buyer = dat_val[,1], dat_tree_val)
```  



### tune and train the GBM model
```{r}
gbmGrid <-  expand.grid(interaction.depth = seq(1, 5, 1), 
                        n.trees = seq(101, 501, 100), 
                        shrinkage = c(0.01, 0.1, 0.5),
                        n.minobsinnode = 10)


fitControl <- trainControl(method = "repeatedcv",
                           number = 5,
                           ## Estimate class probabilities
                           classProbs = TRUE,
                           ## Evaluate performance using 
                           ## the following function
                           summaryFunction = twoClassSummary)

set.seed(1234)
```  


gbmFit <- train(buyer ~ ., data = dat_train, 
                 method = "gbm", 
                 trControl = fitControl, 
                 verbose = FALSE, 
                 tuneGrid = gbmGrid,
                 ## Specify which metric to optimize
                metric = "ROC")
                
                
```{r include=FALSE}
gbm_cv <- read_rds("gbmmodels.rds")
gbm_tr <- read_rds("gbm_tuned.rds")
```  


```{r echo=FALSE}
best_gbm <- gbm_cv$bestTune
best_gbm$n.trees
```  

gbm_tr <- gbm(
  formula = buyer ~ .,
  distribution = "bernoulli",
  data = dat_train,
  n.trees = 401,
  interaction.depth = 5,
  shrinkage = 0.1,
  cv.folds = 5,
  )  
saveRDS(gbm_tr, "gbm_tuned.rds")

```{r echo=FALSE}
pred_gbm <- predict(gbm_tr, newdata = pentathlon_nptb, n.trees = best_gbm$n.trees, type="response")
eval_dat$gbm <- pred_gbm
head(eval_dat)
```



## Evaluate Different Models by Gains
```{r echo=FALSE}
## evaluate models using the test set
evalbin(
  eval_dat,
  pred = c("logit", "ctree", "NN", "gbm"),
  rvar = rvar,
  lev = lev,
  qnt = 30,
  train = "Test",
  data_filter = "training == 1"
) %>% plot(plots = "gains")
```  


## Evaluate Different Models by Performance
```{r echo=FALSE}
## calculate the confusion matrix and various performance metrics for models on the test set
confusion(
  eval_dat,
  pred = c("logit", "ctree", "NN", "gbm"),
  rvar = rvar,
  lev = lev,
  qnt = 30,
  train = "Test",
  data_filter = "training == 1"
) %>% summary()
```  
  
  
***  

> Based on the model evalutaion, we decided to use logistics regression as our final model to predict purchase probability. As we can see, GBM model, though slightly better than the rest model, cannot distinguishing itself too much to logit model. When performance is similar, we prefer the simplier model over the sophisticated ones as the simple model is easier to intepretat and gigging out useful insights. Therefore, we'll conduct the following NPTB analysis using logistics regression model to predict customers' purchase probability.  

***  

  
  
  
### Logistic Model  


**We use training data to train the logistic model and predict on the representative datasets**  

```{r echo=FALSE}
result_reps <- logistic(
  train, 
  rvar = "buyer", 
  evar = c(
    "message", "age", "gender", "income", "education", "children", 
    "freq_endurance", "freq_strength", "freq_water", "freq_team", 
    "freq_backcountry", "freq_winter", "freq_racquet"
  ), 
  lev = "yes", 
  int = c(
    "message:age", "message:gender", 
    "message:income", "message:education", 
    "message:children", "message:freq_endurance", 
    "message:freq_strength", 
    "message:freq_water", 
    "message:freq_team", 
    "message:freq_backcountry", 
    "message:freq_winter", 
    "message:freq_racquet"
  ), 
  check = "standardize"
)
summary(result_reps) 

pred <- predict(result_reps, pred_data = reps, pred_cmd = "message ='endurance'")
reps <- store(reps, pred, name = "p_logit_edur")

pred <- predict(result_reps, pred_data = reps, pred_cmd = "message ='strength'")
reps <- store(reps, pred, name = "p_logit_str")

pred <- predict(result_reps, pred_data = reps, pred_cmd = "message ='water'")
reps <- store(reps, pred, name = "p_logit_watr")

pred <- predict(result_reps, pred_data = reps, pred_cmd = "message ='team'")
reps <- store(reps, pred, name = "p_logit_team")

pred <- predict(result_reps, pred_data = reps, pred_cmd = "message ='backcountry'")
reps <- store(reps, pred, name = "p_logit_backc")

pred <- predict(result_reps, pred_data = reps, pred_cmd = "message ='winter'")
reps <- store(reps, pred, name = "p_logit_wintr")

pred <- predict(result_reps, pred_data = reps, pred_cmd = "message ='racquet'")
reps <- store(reps, pred, name = "p_logit_racq")

```  




### Q1 - Find message to offer
```{r echo=FALSE}
## create new variable(s)
reps <- mutate(reps, to_offer = c("endurance","strength","water","team","backcountry","winter","racquet")[which.pmax(p_logit_edur, p_logit_str, p_logit_watr, p_logit_team,p_logit_backc, p_logit_wintr,p_logit_racq)])

head(reps[, c(1, 33)])
```  


  



### Q2 - the percentage of customers for whom that message maximizes their probability of purchase
```{r echo=FALSE}
result <- pivotr(
  reps, 
  cvars = "to_offer", 
  normalize = "total", 
  tabsort = "desc(n_obs)", 
  nr = 7
)
summary(result)
```  



  



### Q3  Determine the message predicted to lead to the highest expected profit  

#### Approach: use linear regression to predict each buyer's order size using demographic and purchse records as predictors. We use the total order size of buyer == 'yes' as response variable and the same features and interactions as the predictive variables. 

```{r echo=FALSE}
result_os <- regress(
  train, 
  rvar = "total_os", 
  evar = c(
    "message", "age", "gender", "income", "education", "children", 
    "freq_endurance", "freq_strength", "freq_water", "freq_team", 
    "freq_backcountry", "freq_winter", "freq_racquet"
  ),
  int = c(
    "message:age", "message:gender", 
    "message:income", "message:education", 
    "message:children", "message:freq_endurance", 
    "message:freq_strength", 
    "message:freq_water", 
    "message:freq_team", 
    "message:freq_backcountry", 
    "message:freq_winter", 
    "message:freq_racquet"
  ),
  data_filter = "total_os != 0",
)
# summary(result_os)

pred <- predict(result_os, pred_data = reps, pred_cmd = "message='endurance'")
reps <- store(reps, pred, name = "p_os_edur")

pred <- predict(result_os, pred_data = reps, pred_cmd = "message='strength'")
reps <- store(reps, pred, name = "p_os_str")

pred <- predict(result_os, pred_data = reps, pred_cmd = "message='water'")
reps <- store(reps, pred, name = "p_os_watr")

pred <- predict(result_os, pred_data = reps, pred_cmd = "message='team'")
reps <- store(reps, pred, name = "p_os_team")

pred <- predict(result_os, pred_data = reps, pred_cmd = "message='backcountry'")
reps <- store(reps, pred, name = "p_os_backc")

pred <- predict(result_os, pred_data = reps, pred_cmd = "message='winter'")
reps <- store(reps, pred, name = "p_os_wintr")

pred <- predict(result_os, pred_data = reps, pred_cmd = "message='racquet'")
reps <- store(reps, pred, name = "p_os_racq")

head(reps[, 34:40])
```  


### Get profit  

Function to scale predicted purchase probability  

```{r}
p_adj <- function(p){
  p_adj = p / (p + (1 - p) * (1 - 0.01) / 0.01)
  p_adj
}
```  


```{r echo=FALSE}
reps <- reps %>% 
  mutate(ep_edur = p_adj(p_logit_edur)*p_os_edur*0.4,
         ep_str = p_adj(p_logit_str)*p_os_str*0.4,
         ep_watr = p_adj(p_logit_watr)*p_os_watr*0.4,
         ep_team = p_adj(p_logit_team)*p_os_team*0.4,
         ep_backc = p_adj(p_logit_backc)*p_os_backc*0.4,
         ep_wintr = p_adj(p_logit_wintr)*p_os_wintr*0.4,
         ep_racq = p_adj(p_logit_racq)*p_os_racq*0.4,
         to_offer_prof = c("endurance","strength","water","team","backcountry","winter","racquet")[which.pmax(ep_edur, ep_str, ep_watr, ep_team, ep_backc, ep_wintr, ep_racq)])

# names(reps)[49] <- 'to_offer_prof'
# Get suctomized EP

reps <- reps %>% 
  mutate(ep_to_offer = pmax(ep_edur, ep_str, ep_watr, ep_team, ep_backc, ep_wintr, ep_racq))
head(reps[, c(1, 49, 48)])
```  



### Q4  Report for each message, the percentage of customers for whom that message maximizes their expected profit

```{r echo=FALSE}
offer_ep <- pivotr(
  reps, 
  cvars = "to_offer_prof", 
  normalize = "total", 
  tabsort = "desc(n_obs)"
)
summary(offer_ep)
```  


### Q5/ Q6  What expected profit can we obtain, on average, per e-mailed customer if we customize the message to each customer  

* If we customize the message to each customer, expected profit can we obtain, on average, per e-mailed customer is 0.353.  
* If we don't customize, the average expected profit will be as follows:  

```{r echo=FALSE}
result <- explore(
  dataset = reps, 
  vars = c("ep_edur", "ep_str", "ep_watr", "ep_team", "ep_backc", "ep_wintr", "ep_racq", "ep_to_offer"), 
  fun = "mean",
  tabsort = "desc(mean)"
)
summary(result)


```  


### Q7 What is the expected profit per e-mailed customer if every customer is assigned randomly to one of the seven messages  

```{r echo=FALSE}
ep_rand <- mean(rowMeans(reps[, 41:47]))
```
The expected profit per e-mailed customer will be `r format_nr(ep_rand, dec = 3)` if every customer is assigned randomly to one of the seven messages.  


  


### Q8 what improvement could Pentathlon achieve by customizing the message to each customer rather than assigning customers a message randomly  

```{r include=FALSE}
total_ep_rand <- ep_rand * 5000000

total_ep_target <- mean(reps$ep_to_offer) * 5000000

improve <- (total_ep_target - total_ep_rand)/total_ep_rand
improve*total_ep_rand
```  
If customizing the message, total expected profit will be `r format_nr(improve, perc = TRUE)` higher than assigning customers a message randomly; that is,  `r format_nr(improve*total_ep_rand, "$", dec = 0)` more than random message.  


***  

## New Policy  

### Weaknesses:

> 1) Pentathlon has limited promotional emails to two per week based on the previous email frequency test result. Thus under the new policy, customers will receive two emails weekly, one from the highest expected profit department and the other from the second highest expected profit department. It is obviously to see that the frequency of reciving certain department's message declines from 2 emails per week to 1 email per week. Therefore, customers who are interested in the highest department cannot get enough connection with that department and probably reduce their purchase probabilty as a result. 

> 2) The analysis cycle in the new proposal is only the first three weeks of one month, which is too short as customer's purchase probability can be affected by seasonality. As we used the expected profit to determine which two messages to sent, it is likely that for some departments, customer's ordersize is large while the purchase frequency is low because of seasonlity. So in such short cycle, it is hard for us to observe customer's purchase behavior, and also expensive for the company to conduct useless analysis.

### Improvement Suggestion:

> 1) A possible solution to the declining frequency issue is that, combining the top two departments' message content into one email and send to customers twice per week. In this case, customers will receive optimal emails regarding both departments, and will not be easily tired of only one department's message at the same time. 

> 2) We can extend the analysis cycle to three months, therefore the purchase behavior of customer can be more clear and more persuasive.

