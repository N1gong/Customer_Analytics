---
title: "Pentathlon II"
output: html_document
---

```{r r_setup, include = FALSE}
## initial settings
knitr::opts_chunk$set(
  comment = NA,
  echo = TRUE,
  error = TRUE,
  cache = FALSE,
  message = FALSE,
  dpi = 96,
  warning = FALSE
)

## width to use when printing tables etc.
options(
  width = 250,
  scipen = 100,
  max.print = 5000,
  stringsAsFactors = FALSE
)
```

<style>
.table {
  width: auto;
}
ul, ol {
  padding-left: 18px;
}
pre, code, pre code {
  overflow: auto;
  white-space: pre;
  word-wrap: normal;
  background-color: #ffffff;
}
</style>

## Setup

Create an Rmarkdown document in which you calculate the CLV for each of the plans over an 8 week periods. The relevant data is in `data/pentathlon-II.xls` Also, use the average subscription churn and revenue numbers provided in `data/pentathlon-II-avg.csv` to simulate the effect of the different email frequencies over a 104 week period and generate a line plot to compare the five CLV curves. Are your results consistent with your answer to question 3 in the pentathlon-II.pdf file on Dropbox? Why (or why not)?

## Hints

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>. Go to http://commonmark.org/help/ for a 10-minute interactive Markdown tutorial

## Analysis

Load both the `data/pentathlon-II.xls` and `data/pentathlon-II-avg.csv` for use in your analysis. Note that you still have to calculate the weekly discount rate based on the annual discount rate mentioned below.

The variables in `data/pentathlon-II-avg.csv` are:

* `schurn` is the average subscription churn over the 8 weeks of the test
* `rev_sub` is the average revenue from subscribers
* `rev_unsub` is the average revenue from non-subscribers

A few assumptions to start with:

```
weeks <- 1:104
discount <- .1 ## annual discount rate
cogs <- .6
```
```{r include=FALSE}
library(tidyverse)
```


## Loading data
```{r include=FALSE}
One <- readxl::read_excel("data/pentathlon-II.xls", range = "B1:I4") 

Two <- readxl::read_excel("data/pentathlon-II.xls", range = "B6:I9") 

Three <- readxl::read_excel("data/pentathlon-II.xls", range = "B11:I14") 

Four <- readxl::read_excel("data/pentathlon-II.xls", range = "B16:I19") 

Five <- readxl::read_excel("data/pentathlon-II.xls", range = "B21:I24") 

Average <- read_csv("data/pentathlon-II-avg.csv")
```

Create a code chunk that contains a function that you can call to calculate the CLV for each of the 5 email plans.

```{r}
## insert CLV function below
## determine what arguments the function needs to generate the required
## return value
clv <- function(D, subs, unsubs, churn, cogs, T, time) {
  
  # D is annual discount rate
  # subs is the average weekly revenue for test customers who received emails
  # unsubs is the average weekly revenue for test customers who did not receive emails
  # churn is the weekly churn rate
  # cogs is the cost of a unit goods sold
  # T is the total period in a year, for converting discount rate
  # time is the measuring period
  
  d <- (1 +D)^(1/T) - 1
  retained <- cumprod(c(1, (1-churn)))
  left <- 1 - retained
  prof_s <- subs*(1-cogs)
  prof_un <- unsubs*(1-cogs)
  exp_profit <- retained*prof_s + left*prof_un
  PV_exp_profit <- (unlist(exp_profit / (1 + d)^time) + unlist(exp_profit / (1 + d)^(time-1))) * 0.5
 
  CLV <- cumsum(PV_exp_profit)
  
  # return(t(unname(CLV)))
  
  return(CLV)
}

```

Extracting the information needed for CLV calculation
```{r}
## One email per week
subs1 <-One[2,]
unsubs1 <- One[3, ]
churn1 <- unlist(unname(One[1,1:7]))

## Two emails per week
subs2 <-Two[2,]
unsubs2 <- Two[3, ]
churn2 <- unlist(unname(Two[1,1:7]))

## Three per week
subs3 <-Three[2,]
unsubs3 <- Three[3, ]
churn3 <- unlist(unname(Three[1,1:7]))

## Four per week
subs4 <-Four[2,]
unsubs4 <- Four[3, ]
churn4 <- unlist(unname(Four[1,1:7]))

## Five per week
subs5 <-Five[2,]
unsubs5 <- Five[3, ]
churn5 <- unlist(unname(Five[1,1:7]))
```

Next, create a tibble with 6 columns. Five columns for the CLV series for each of the plans and one column for the `weeks` variable defined above. Call the `clv` function you created above to fill-in the columns.

```{r}
## create the tibble (data.frame)
cogs=0.6

CLV_eight_week <- data.frame(week=c(1:8))

CLV_eight_week <- CLV_eight_week %>% 
  mutate(One = clv(D=0.1, subs1, unsubs1, churn1, cogs, T=52, time=1:8),
         Two = clv(D=0.1, subs2, unsubs2, churn2, cogs, T=52, time=1:8),
         Three = clv(D=0.1, subs3, unsubs3, churn3, cogs, T=52, time=1:8),
         Four = clv(D=0.1, subs4, unsubs4, churn4, cogs, T=52, time=1:8),
         Five = clv(D=0.1, subs5, unsubs5, churn5, cogs, T=52, time=1:8))


CLV_eight_week
```

Next, generate three line plots that compare the CLV curves for each of the five plans. The first graphs should plot weeks 1 through 8. The second graph should plot weeks 1 through 52 and the final graph should show weeks 1 through 104.  

#### Graph one (for 8 weeks using test data)
```{r echo=FALSE}
## generate graph 1
radiant.data::visualize(CLV_eight_week, xvar = "week", yvar = c("One", "Two","Three", "Four", "Five" ), comby = TRUE, type = "line", labs = list(y = "CLV", color = ""))
```


#### Graph one (for 8 weeks using average rate and revenue)
```{r echo=FALSE}
## generate graph one using average rate
short_clv <- data.frame(week=c(1:8)) %>% 
  mutate(One = c(clv(D=0.1, rep(Average$rev_sub[1],8), rep(Average$rev_unsub[1],8), rep(Average$schurn[1],7), cogs, T=52, time=1:8)),
         Two = c(clv(D=0.1, rep(Average$rev_sub[2],8), rep(Average$rev_unsub[2],8), rep(Average$schurn[2],7), cogs, T=52, time=1:8)),
         Three = c(clv(D=0.1, rep(Average$rev_sub[3],8), rep(Average$rev_unsub[3],8), rep(Average$schurn[3],7), cogs, T=52, time=1:8)),
         Four = c(clv(D=0.1, rep(Average$rev_sub[4],8), rep(Average$rev_unsub[4],8), rep(Average$schurn[4],7), cogs, T=52, time=1:8)),
         Five = c(clv(D=0.1, rep(Average$rev_sub[5],8), rep(Average$rev_unsub[5],8), rep(Average$schurn[5],7), cogs, T=52, time=1:8)))

radiant.data::visualize(short_clv, xvar = "week", yvar = c("One", "Two","Three", "Four", "Five" ), comby = TRUE, type = "line", labs = list(y = "CLV", color = ""))
```

#### Graph two (for 52 weeks)
```{r echo=FALSE}
## generate graph 2
year_week <- data.frame(week=c(1:52)) %>% 
  mutate(One = c(clv(D=0.1, rep(Average$rev_sub[1],52), rep(Average$rev_unsub[1],52), rep(Average$schurn[1],51), cogs, T=52, time=1:52)),
         Two = c(clv(D=0.1, rep(Average$rev_sub[2],52), rep(Average$rev_unsub[2],52), rep(Average$schurn[2],51), cogs, T=52, time=1:52)),
         Three = c(clv(D=0.1, rep(Average$rev_sub[3],52), rep(Average$rev_unsub[3],52), rep(Average$schurn[3],51), cogs, T=52, time=1:52)),
         Four = c(clv(D=0.1, rep(Average$rev_sub[4],52), rep(Average$rev_unsub[4],52), rep(Average$schurn[4],51), cogs, T=52, time=1:52)),
         Five = c(clv(D=0.1, rep(Average$rev_sub[5],52), rep(Average$rev_unsub[5],52), rep(Average$schurn[5],51), cogs, T=52, time=1:52)))


radiant.data::visualize(year_week, xvar = "week", yvar = c("One", "Two","Three", "Four", "Five" ), comby = TRUE, type = "line", labs = list(y = "CLV", color = ""))

```  
  
  
#### Graph three (for 104 weeks)  

```{r echo=FALSE}
## generate graph 3
dualyr_week <- data.frame(week=c(1:104)) %>% 
  mutate(One = c(clv(D=0.1, rep(Average$rev_sub[1],104), rep(Average$rev_unsub[1],104), rep(Average$schurn[1],103), cogs, T=52, time=1:104)),
         Two = c(clv(D=0.1, rep(Average$rev_sub[2],52*2), rep(Average$rev_unsub[2],52*2), rep(Average$schurn[2],103), cogs, T=52, time=1:104)),
         Three = c(clv(D=0.1, rep(Average$rev_sub[3],52*2), rep(Average$rev_unsub[3],52*2), rep(Average$schurn[3],103), cogs, T=52, time=1:104)),
         Four = c(clv(D=0.1, rep(Average$rev_sub[4],52*2), rep(Average$rev_unsub[4],52*2), rep(Average$schurn[4],103), cogs, T=52, time=1:104)),
         Five = c(clv(D=0.1, rep(Average$rev_sub[5],52*2), rep(Average$rev_unsub[5],52*2), rep(Average$schurn[5],103), cogs, T=52, time=1:104)))

radiant.data::visualize(dualyr_week, xvar = "week", yvar = c("One", "Two","Three", "Four", "Five" ), comby = TRUE, type = "line", labs = list(y = "CLV", color = ""))

```
## Questions

### Q1 Calculate the 8-week CLV for each of the five tested e-mail frequencies.

```{r echo=FALSE}
paste0("The 8-week CLV for one email per week is: ", CLV_eight_week$One[8])
paste0("The 8-week CLV for two emails per week is: ", CLV_eight_week$Two[8])
paste0("The 8-week CLV for three emails per week is: ", CLV_eight_week$Three[8])
paste0("The 8-week CLV for four emails per week is: ", CLV_eight_week$Four[8])
paste0("The 8-week CLV for five email per week is: ", CLV_eight_week$Five[8])
```



### Q2 What e-mail frequency should Pentathlon adopt? Motivate your recommendation.

>From the above analytical result, we can see the one email per week frequency shows an obvious weakness in 8-week total CLV. The 2,3,4,5 email frequencies almost make no differences for the 2 weeks total CLV but the curves gradually spread out afterwards. The current frequency - 4 emails per week, consistently generated lower CLV compared to 2 and 3 emails respectively after 2 weeks, and the gap stretches further after week five. Therefore, the analytical result implies the fact that the company should adopt an email frequency between 2 to 3 per week as they outperform other strategies throughout the 8 weeks period.  

>Now letâ€™s look into the two and three email frequencies. 3 emails per week is the winner frequency in the test, exceeding 2-email frequency by $0.01 per customer, or $100 per 10,000 customers total 8-week CLV.So looking at the test outcome and the short-term trend of the average total revenue, 3-email frequency has the highest cumulative CLV and higher profit than 2-email. **We would recommend 3 emails per week if the company want to seek a short-term performance.**

>However, if we look at the cumulative difference in expected profit of 3-email over 2-email, the plot implies something different. The lowest cumulated difference is around -0.03 while the greatest is only around 0.01 which means 3-email has the potential risk to be much lower than 2-email in expected profit; in fact, at week8 the expected profit from 3-email is already lower than that of 2-email;meanwhile, the graph also shows a tendency of the difference to lower further in the near future. Plus, the total average revenue graph suggests a tendency of 3-email's profit to go down in the near term as well. Therefore, we strongly suspect that 3-email's performace can last long. **if Pentathlon want to gain a sustainable advantage in exploit customer values for the long run, we would recommend 2 emails per weeks as the safest yet very effective email frequency.**  


```{r include=FALSE}
prof <- function(D, subs, unsubs, churn, cogs, T, time) {
  
  d <- (1 +D)^(1/T) - 1
  retained <- cumprod(c(1, (1-churn)))
  left <- 1 - retained
  prof_s <- subs*(1-cogs)
  prof_un <- unsubs*(1-cogs)
  exp_profit <- unlist(retained*prof_s) + unlist(left*prof_un)
  # PV_exp_profit <- (unlist(exp_profit / (1 + d)^time) + unlist(exp_profit / (1 + d)^(time-1))) * 0.5
  
  exp_profit
  
}
```  

*Plot cumulated differences in expected profit of 3-email minus 2-email over 8 weeks*
```{r echo=FALSE}

pro8 <- data.frame(week=c(1:8))
pro8 <- pro8 %>% 
  mutate(One = prof(D=0.1, subs1, unsubs1, churn1, cogs, T=52, time=1:8),
         Two = prof(D=0.1, subs2, unsubs2, churn2, cogs, T=52, time=1:8),
         Three = prof(D=0.1, subs3, unsubs3, churn3, cogs, T=52, time=1:8),
         Four = prof(D=0.1, subs4, unsubs4, churn4, cogs, T=52, time=1:8),
         Five = prof(D=0.1, subs5, unsubs5, churn5, cogs, T=52, time=1:8))

plot(cumsum(pro8$Three-pro8$Two), type = "b", pch = 19, 
     col = "red", xlab = "week", ylab = "difference_3over2")

```  
  
*Plot average subscriber and unsubscriber revenue*
```{r echo=FALSE}
total_two <- subs2+unsubs2
total_three <- subs3+unsubs3

# plot(unlist(total_two), type = 'l')
par(mfrow=c(1,2))
plot(unlist(total_two), type = "b", pch = 19, 
     col = "red", xlab = "week", ylab = "2emails_total_avg")
plot(unlist(total_three), type = "b", pch = 19, 
     col = "red", xlab = "week", ylab = "3emails_total_avg")
```
  
  

### Q3 What e-mail frequency would you recommend if you considered a longer time horizon? Why? Make your argument without formally extending the CLV calculation.  

>Using the average churn and average spending per subscriber and un-subscriber, the frequency of 4 or 5 per week is unable to provide the company a satisfying outcome in the long run; interestingly, the one email frequency which was beaten by the other frequencies in the short period, exhibits a strong ability in bringing more value to the company. This proves that an aggressive email frequency will hurt the profitability in the long run.  


>The analytical result shows that, considering a longer period, typically around a year, the best frequency should be set at two emails per week because the projected 52-week total CLV under it exceeds the other frequencies.  


>To summary, we recommend the **2 emails per week** frequency to the company considering a longer time horizon.  


### Q4 Calculate the CLV for each of the plans after 104 weeks using the average churn and revenue numbers provided on GitLab. Generate a line plot to compare the five CLV curves. Are your results consistent with your answer to question 3? Why (or why not)?  

```{r echo=FALSE}
paste0("The 104-week CLV for one email per week is: ", dualyr_week$One[104])
paste0("The 104-week CLV for two emails per week is: ", dualyr_week$Two[104])
paste0("The 104-week CLV for three emails per week is: ", dualyr_week$Three[104])
paste0("The 104-week CLV for four emails per week is: ", dualyr_week$Four[104])
paste0("The 104-week CLV for five email per week is: ", dualyr_week$Five[104])
```  


> From the 104-week analytical result, we can see the best frequency looking out for 2 years is still two emails per week, slightly higher than the second highest total CLV calculated under one email per week. It seems that the one-email strategy is catching up rapidly as we looking at a longer period in the analysis. Our result from analyzing 104-week clv is aligned with the findings in question 3 - two email per week is the optimum email frequency, though one email per week demonstrated its great potential when looking at longer period. 

>The reason why the result consist in our analysis is that, one-email has a lower clv to begin with and a flatter clv curve spread out as time goes by compared to two-email frequency, which has a higher clv to start with and a stiffer curve. The differences between them flat out as we increase the number of weeks from around 50 weeks (see graph below), so the two CLV curves will be approximatly parallal in the long-term with two-email CLV curve over the one-email curve. Therefore, the total clv under 2-email will consistently surpassing 1-email for both 1 year and 2 year time horizon.  
  
    
*Plot differences in CLV of 2-email minus 1-email*

```{r echo=FALSE}
Diff <- dualyr_week$Two-dualyr_week$One

plot(Diff, type = "l", 
     col = "blue", xlab = "week", ylab = "Difference")
```

  

### Q5 Discuss at least two limitations of the current test. How would you address these limitations?  


**Limitation One**  

Customers who continuously purchase product from the company without opt out the email is not necessarily the proof of the effectiveness of that specific email frequency. These customers may not have a habit to check their promotion emails or they may leave an infrequently used address to the company just not to be bothered, and those facts don't affect their personal preference to Pentathlon's products. As they may never seen the email at all, they probably will never opt-out either, and if such kind of customers are not randomly distributed among the test groups, the CLV calculated for each email frequency can be misleading since the email in this way is irrelevant to the customer spending data at all.

One way to address this issue is to trace how customer make the final purchase and to track if the customer ever opened the email at all. For example, the company can track the link that particular customer bought product through, and see if it is the one made available in the promotional email. If more customers make purchase because they saw the email under certain frequency than that under the other frequencies, then this data can speaker to more of the email strategy than the current test.

**Limitation Two**  

Each group receives emails from a particular department each week, the problem with such design is that the company has 7 special department stores selling sports equipment that ranges from cycling, yoga, sailing, rugby, to hiking, skiing, tennis and so on. It is obvious to tell that a certain customer can hardly be interested in all the varieties of product, or not every variety of the product is suitable for the season the test was conducted. Therefore, such grouping and test method has embedded a potential driver to affect the test outcome other than just email frequency. People in the 5-email per week group deciding to unsubscribe in the first week might well due to they have no interests or needs of that particular kind of product and yet they received such kind of emails almost every day which led them to unsubscribe soon as they can; however, had they receive emails of other variety that fits better of their needs, they may not churn that much.

One can argue that customersâ€™ CLV is particularly high in a group is because that group has a wider interest in different kinds of sports activities or the majority in the group can enjoy many kinds of sports due to the good weather all year round (like California vs. Michigan). In this case, such kind of noise drivers will weaken the ability of email frequency to explain the CLV outcome.

In order to minimize this test deficiency, the group should be further divided based on each department's client base and split its own client base into 5 frequencies so that to be assured the churn and customer spending won't be the result of customersâ€™ own interests or weather factors but purely affected by the frequency itself.  


  




Please generate a *reproducible* Notebook or HTML report with all your results and your answers to the questions listed in the pentathlon-II.pdf file on Dropbox.

When you have finished editing this Rmarkdown document make sure to save, commit, and push it to GitLab. We will collect all the rmarkdown files from GitLab after the due date.
